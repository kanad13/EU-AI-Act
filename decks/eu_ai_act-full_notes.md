# links

- **EU AI Act**
  - EU AI Act - Full Text [link](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32024R1689)
  - Up-to-date developments and analyses of the EU AI Act -[website](https://artificialintelligenceact.eu)
  - European Parliament Think Tank [link](<https://www.europarl.europa.eu/thinktank/en/document/EPRS_BRI(2021)698792>)
  - high level summary [link](https://artificialintelligenceact.eu/high-level-summary/)
  - press FAQ [link](https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683)
  - AI Act Explorer [link](https://artificialintelligenceact.eu/ai-act-explorer/)
  - EU AI Act Compliance Checker [link](https://artificialintelligenceact.eu/assessment/eu-ai-act-compliance-checker/)
  - AI Pact [link](https://digital-strategy.ec.europa.eu/en/policies/ai-pact)
- **GDPR**
  - [GDPR full text](https://eur-lex.europa.eu/EN/legal-content/summary/general-data-protection-regulation-gdpr.html)
  - impact of the GDPR on AI - [link](https://www.europarl.europa.eu/RegData/etudes/STUD/2020/641530/EPRS_STU%282020%29641530_EN.pdf)
  - Legal bases in data protection for the use of artificial intelligence - [link](https://www.baden-wuerttemberg.datenschutz.de/legal-bases-in-data-protection-for-ai/)
  - french CNIL Guidelines
    - short summary [link](https://secureprivacy.ai/blog/cnil-guidelines-ai-gdpr-compliance)
    - self-assessment guide [link](https://www.cnil.fr/en/self-assessment-guide-artificial-intelligence-ai-systems)
  - AI & GDPR - [legamart](https://legamart.com/articles/ai-and-gdpr/)

1. [links](#links)
2. [Overview and Purpose](#overview-and-purpose)
   1. [About EU AI Act](#about-eu-ai-act)
   2. [Need for EU AI Act](#need-for-eu-ai-act)
   3. [Scope of Application](#scope-of-application)
   4. [Define AI Systems](#define-ai-systems)
3. [Risk based approach](#risk-based-approach)
   1. [summary - risk based approach](#summary---risk-based-approach)
   2. [details - risk based approach](#details---risk-based-approach)
4. [High-Risk AI Systems](#high-risk-ai-systems)
   1. [responsibilities of providers of high-risk AI systems (Article 16)](#responsibilities-of-providers-of-high-risk-ai-systems-article-16)
   2. [responsibilities of deployers of high-risk AI systems (Article 26)](#responsibilities-of-deployers-of-high-risk-ai-systems-article-26)
   3. [Conformity Assessment (Article 43)](#conformity-assessment-article-43)
   4. [EU Database (Article 71)](#eu-database-article-71)
5. [General Purpose AI Systems](#general-purpose-ai-systems)
   1. [responsibilities of providers of GPAI models (Article 53)](#responsibilities-of-providers-of-gpai-models-article-53)
   2. [AI Office (Article 64)](#ai-office-article-64)
6. [Governance and Enforcement](#governance-and-enforcement)
   1. [European level](#european-level)
   2. [National level](#national-level)
   3. [European Artificial Intelligence Board (Article 65)](#european-artificial-intelligence-board-article-65)
   4. [Advisory Forum (Article 67)](#advisory-forum-article-67)
   5. [AI Office (Article 64)](#ai-office-article-64-1)
   6. [Surveillance \& Fines](#surveillance--fines)
7. [Support for Innovation and SMEs](#support-for-innovation-and-smes)
   1. [AI Regulatory Sandboxes (Article 57)](#ai-regulatory-sandboxes-article-57)
   2. [Real World Testing (Article 60)](#real-world-testing-article-60)
8. [Right to Explanation](#right-to-explanation)
9. [International Cooperation](#international-cooperation)
10. [Relationship with Other EU Laws](#relationship-with-other-eu-laws)
11. [Promoting AI Literacy](#promoting-ai-literacy)
12. [Environmental Considerations](#environmental-considerations)
13. [Codes of Conduct](#codes-of-conduct)
14. [AI Pact](#ai-pact)
15. [Implementation Timeline](#implementation-timeline)
16. [Penalties for Infringement](#penalties-for-infringement)
17. [How EU AI Act builds on GDPR](#how-eu-ai-act-builds-on-gdpr)
    1. [Scope and Application](#scope-and-application)
    2. [Rights of Individuals](#rights-of-individuals)
    3. [Risk-Based Approach](#risk-based-approach-1)
    4. [Accountability and Documentation](#accountability-and-documentation)
    5. [Automated Decision-Making](#automated-decision-making)
    6. [Transparency and Explainability](#transparency-and-explainability)
    7. [Notification of Incidents](#notification-of-incidents)
    8. [Compliance and Penalties](#compliance-and-penalties)
18. [Essential Activities for Data Governance Teams](#essential-activities-for-data-governance-teams)
    1. [Data Quality and Governance (Article 10)](#data-quality-and-governance-article-10)
    2. [Bias Detection and Mitigation (Article 10)](#bias-detection-and-mitigation-article-10)
    3. [Technical Documentation (Article 10)](#technical-documentation-article-10)
    4. [Record-Keeping and Logging (Article 10)](#record-keeping-and-logging-article-10)
    5. [Transparency and User Information (Article 10)](#transparency-and-user-information-article-10)
    6. [Human Oversight (Article 10)](#human-oversight-article-10)
19. [Essential Activities for AI/ML Teams](#essential-activities-for-aiml-teams)
    1. [Algorithmic Impact Assessments](#algorithmic-impact-assessments)
    2. [Training Data Management](#training-data-management)
    3. [Synthetic Data Generation](#synthetic-data-generation)
    4. [AI Model Lifecycle Management](#ai-model-lifecycle-management)
    5. [Model Documentation](#model-documentation)
    6. [Audit Trails for AI Decisions](#audit-trails-for-ai-decisions)
    7. [Transparency and Explainability](#transparency-and-explainability-1)
    8. [Ongoing Compliance Monitoring](#ongoing-compliance-monitoring)

# Overview and Purpose

## About EU AI Act

The EU AI Act is the world's first comprehensive law on artificial intelligence. Its key aims are to:

- Address risks to health, safety and fundamental rights posed by AI systems (Recital 1, 5)
- Protect democracy, rule of law and the environment (Recital 5)
- Enhance trust in AI to increase adoption and innovation (Recital 6)
- Provide legal certainty for AI providers and users (Recital 6)
- Harmonize rules across the EU to prevent market fragmentation (Recital 6)

## Need for EU AI Act

- AI systems may jeopardise fundamental rights such as the right to non-discrimination, freedom of expression, human dignity, personal data protection and privacy. (Recital 4)
- Act aims to develop a 'human-centric' approach to AI to ensure that Europeans can benefit from new technologies developed and functioning according to the EU's values and principles. (Recital 5)

## Scope of Application

- The Act applies to:
  - AI system providers and users in the EU (Article 2(1))
  - Non-EU providers and users when the output is used in the EU (Article 2(1))
- Exclusions:
  - AI for military, defense, or national security (Article 2(3))
  - AI used only for research and development pre-market (Article 2(6))

## Define AI Systems

- An 'AI system' is defined as (Article 3(1)):
  - "A machine-based system designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments."

# Risk based approach

## summary - risk based approach

- The Act takes a risk-based approach, with different requirements based on the level of risk posed by an AI system (Recital 14):
  - `Unacceptable risk` (Article 5)
    - Certain AI practices are prohibited
    - e.g. social scoring systems, real-time remote biometric identification
  - `High risk` (Article 6, Annex III)
    - Strict requirements for development and use
    - AI in critical infrastructure, CV screening tools, credit scoring
  - `Limited risk` (Article 50)
    - Such systems have transparency obligations
    - e.g. chatbots must inform users they are interacting with an AI
  - `Minimal risk`
    - Majority of AI systems fall into this category and are not subject to new requirements under the AI Act
    - e.g. spam filters, AI-enabled video games

## details - risk based approach

### Unacceptable Risk (Article 5)

- AI systems in this category are prohibited due to their potential to cause severe harm to individuals or society.
- Examples include:
  - Social scoring systems used by public authorities (Article 5(1)(c))
  - Exploitation of vulnerabilities of specific groups (e.g., children, disabled persons) (Article 5(1)(b))
  - Real-time remote biometric identification in public spaces for law enforcement (with limited exceptions) (Article 5(1)(h))
  - Subliminal manipulation causing physical or psychological harm (Article 5(1)(a))

### High Risk (Article 6, Annex III)

- These AI systems pose significant risks to health, safety, or fundamental rights and are subject to strict requirements.
- Examples include:
  - AI in critical infrastructure (e.g., water, gas, electricity supply) (Annex III, 2)
  - AI in education (e.g., determining access to educational institutions) (Annex III, 3)
  - AI in employment (e.g., CV-screening tools, interview evaluation systems) (Annex III, 4)
  - AI in essential private and public services (e.g., credit scoring, emergency services dispatch) (Annex III, 5)
  - AI in law enforcement (e.g., crime forecasting, evidence reliability assessment) (Annex III, 6)
  - AI in migration and border control (e.g., verification of travel documents) (Annex III, 7)
  - AI in administration of justice (e.g., fact interpretation in court cases) (Annex III, 8)

### Limited Risk (Article 50)

- These AI systems have specific transparency obligations.
- Examples include:
  - Chatbots: Must inform users they are interacting with an AI (Article 50(1))
  - Emotion recognition systems: Must inform users of their operation (Article 50(3))
  - Deep fake systems: Must disclose that the content is artificially generated or manipulated (Article 50(4))

### Minimal Risk

- This category is not explicitly defined in the Act but is implied for AI systems not falling into the other categories. - The majority of AI systems fall into this category and are not subject to new requirements under the AI Act.
- Examples of such systems include:
  - AI-enabled video games
  - Spam filters
  - Inventory management systems
  - AI used in scientific research

# High-Risk AI Systems

## responsibilities of providers of high-risk AI systems (Article 16)

- Providers of high-risk AI systems must comply with strict requirements before placing them on the market, including:
  - `Identify and mitigate risks` (Article 9)
    - Identify and analyze known and foreseeable risks
    - Estimate and evaluate risks that may emerge when the system is used
    - Evaluate other possible emerging risks
    - Adopt suitable risk mitigation measures
  - `data governance` (Article 10)
    - examine data for biases
    - ensure data is relevant, representative, free of errors and complete
    - consider data protection and privacy implications
    - implement data minimization practices
    - allow for the traceability and auditability of the data used
  - `technical documentation` (Article 11)
    - maintain detailed documentation on system development and functioning
    - include information on system architecture, algorithms, data, training processes, and performance metrics
  - `record keeping` (Article 12)
    - enable automatic recording of events ('logs') throughout the system's lifecycle
    - ensure traceability and auditability e.g. periods of each use, reference database used, etc.
  - `transparency` (Article 13)
    - inform users about system capabilities and limitations
    - include details on performance, intended purpose, and maintenance requirements
  - `human oversight` (Article 14)
    - ensure meaningful oversight by humans to prevent/minimize risks
  - `accuracy, robustness, and cybersecurity` (Article 15)
    - be resilient to errors, faults, and inconsistencies
    - implement cybersecurity measures
  - `providers must also`
  - implement a quality management system (Article 17)
  - draw up an EU declaration of conformity (Article 47)
  - affix the CE marking to compliant systems (Article 48)
  - conduct post-market monitoring (Article 72)
  - report serious incidents and malfunctioning (Article 73)

## responsibilities of deployers of high-risk AI systems (Article 26)

- the Act also places some obligations on **deployers** of high-risk AI systems
  - Use the system in accordance with the instructions of use (Article 26(1))
  - Ensure human oversight when using the system (Article 26(2))
  - Monitor the operation for possible risks (Article 26(5))
  - Inform the provider or distributor about any serious incidents or malfunctioning (Article 26(5))
  - Conduct a data protection impact assessment when required by EU data protection law (Article 26(9))
  - Keep logs automatically generated by the high-risk AI system, to the extent such logs are under their control (Article 26(6))

## Conformity Assessment (Article 43)

- Mandatory pre-market assessment for high-risk AI systems
- Assessment methods:
  - Self-assessment by provider (most systems) (Article 43(2))
  - Third-party assessment (e.g., remote biometric identification) (Article 43(1))
- Re-assessment required after substantial modifications (Article 43(4))
- Successful assessment results in:
  - EU declaration of conformity (Article 47)
  - CE marking affixation (Article 48)

## EU Database (Article 71)

- The EU AI Act establishes an EU database for high-risk AI systems with the following features:
  - Centralized registration of stand-alone high-risk AI systems (Article 71(1))
  - Public accessibility, except for law enforcement, immigration, asylum and border control AI systems, which are registered in a separate secure section (Article 71(4))
  - Required information includes (Article 71(2)):
    - Details of the provider and the AI system
    - Intended purpose and key characteristics
    - Status of the system (on market, recalled, etc.)
    - Conformity assessment details
  - Deployers that are public bodies must also register their use of high-risk AI systems (Article 71(3))
  - Aims to increase transparency and facilitate oversight by authorities and the public
  - The Commission is responsible for developing and maintaining the database (Article 71(1))

# General Purpose AI Systems

## responsibilities of providers of GPAI models (Article 53)

- All providers of GPAI models must:
  - Prepare technical documentation on the model (Article 53(1)(a))
  - Provide information to downstream providers to enable their compliance (Article 53(1)(b))
  - Establish a policy to respect copyright law (Article 53(1)(c))
  - Publish a summary of the content used to train the model (Article 53(1)(d))
- Providers can demonstrate compliance through:
  - Adhering to voluntary codes of practice (Article 53(4))
  - Complying with harmonized standards (when available) (Article 53(4))
  - Demonstrating alternative adequate means (Article 53(4))

## AI Office (Article 64)

**Purpose and Establishment**

- Part of European Commission to develop EU AI expertise and capabilities
- Monitors implementation and compliance of AI Act, especially for general-purpose AI (GPAI)

**Key Responsibilities**

1. Oversee GPAI models (Chapter V of AI Act) (Article 88)

   - Monitor compliance
   - Conduct evaluations and investigations
   - Request information from providers
   - Impose corrective measures or fines

2. Maintain public list of GPAI models with systemic risk (Article 52(6))

3. Encourage codes of practice for GPAI providers, covering (Article 56)
   - Technical documentation requirements
   - Systemic risk identification
   - Risk management measures

**Powers**

- Request information, documentation, and model access from GPAI providers (Article 91)
- Enforce compliance measures (Article 93)

# Governance and Enforcement

The Act establishes a multi-level governance framework:

## European level

- AI Office: Set up within the Commission to oversee implementation, particularly for GPAI (Article 64)
- European Artificial Intelligence Board: Comprising Member State representatives to facilitate harmonized application (Article 65)
- Advisory Forum: Stakeholder group to provide input on implementation (Article 67)

## National level

- Market Surveillance Authorities: Designated by each Member State to monitor compliance and conduct investigations (Article 74)
- Notifying Authorities: To assess and designate conformity assessment bodies (Article 28)

## European Artificial Intelligence Board (Article 65)

- Composition: High-level representatives from Member States and the European Data Protection Supervisor
- Role: Advise and assist the Commission and Member States in implementing the Act
- Tasks: Issue opinions, recommendations, and guidance on various aspects of the Act
- Subgroups: Can establish specialized subgroups for specific issues

## Advisory Forum (Article 67)

- Composition: Representatives from industry, civil society, and academia
- Role: Provide technical expertise and stakeholder input
- Tasks: Prepare opinions, recommendations, and written contributions on request

## AI Office (Article 64)

- Powers: Can request information, conduct evaluations, and impose corrective measures on GPAI model providers
- Responsibilities: Monitor compliance, investigate possible infringements, and coordinate with national authorities
- Resources: Staffed with AI experts, legal professionals, and technical specialists

## Surveillance & Fines

Key enforcement provisions include:

- Powers for market surveillance authorities to access data, conduct audits, and require corrective actions (Article 74)
- Significant administrative fines for non-compliance (Article 99):
  - Up to €35 million or 7% of global turnover for prohibited practices
  - Up to €15 million or 3% for other violations
  - Lower maximums for SMEs and startups
- Right for individuals to lodge complaints with market surveillance authorities (Article 85)
- Protections for whistleblowers reporting violations (Article 87)

The Commission has direct enforcement powers over providers of GPAI models with systemic risk, including the ability to conduct investigations and impose fines (Article 88, 101).

# Support for Innovation and SMEs

The Act includes several measures to support innovation and reduce burden on SMEs:

## AI Regulatory Sandboxes (Article 57)

- Controlled environments to test innovative AI systems under regulatory oversight
- At least one sandbox to be established in each Member State by August 2026 (Article 57(1))
- Priority access for SMEs and startups (Article 62(1)(a))
- Provide legal certainty and supervisory guidance
- Enable regulators to gain early understanding of innovative AI applications
- Participants still liable for any harm caused during testing (Article 59(12))

## Real World Testing (Article 60)

- Framework for limited scale testing of high-risk AI systems in real world conditions
- Subject to safeguards and time limits:
  - Maximum duration of 6 months, extendable once for an additional 6 months (Article 60(4)(f))
  - Requirement for informed consent from participants (Article 61)
  - Obligation to monitor for risks and halt testing if necessary (Article 60(7))
- Requires notification to and approval from market surveillance authorities (Article 60(4)(a,b))

# Right to Explanation

The Act introduces a right to explanation for decisions based on high-risk AI systems (Article 86):

- Applies to decisions that produce legal effects or similarly significantly affect individuals
- Explanations must be clear and meaningful
- Should enable individuals to understand the role of the AI system in the decision-making procedure and the main elements of the decision taken
- Aims to help affected persons exercise their rights effectively
- Does not apply where existing EU law already provides for this right

# International Cooperation

The Act emphasizes international cooperation on AI governance:

- Commitment to promoting EU's human-centric approach to AI globally
- Engagement in bilateral and multilateral forums on AI governance
- Provisions for mutual recognition of conformity assessments with third countries (Article 39)
- Encouragement of international standards alignment
- Consideration of global competitiveness in AI development
- Cooperation on addressing global challenges and risks posed by AI

# Relationship with Other EU Laws

The AI Act is designed to complement existing EU legislation:

- General Data Protection Regulation (GDPR): Builds on GDPR principles for processing personal data, adding AI-specific requirements
- Product Safety Legislation
- Digital Services Act: Aligns with transparency requirements for online platforms using AI
- Machinery Regulation: Coordinates requirements for AI systems integrated into machinery

# Promoting AI Literacy

The Act promotes AI literacy (Article 4):

- Providers and deployers must ensure their staff have sufficient AI literacy
- Considers technical knowledge, experience, education, and training of staff
- Takes into account the context in which the AI system will be used
- Aims to enable informed development, operation, and use of AI systems
- The AI Office is tasked with promoting AI literacy tools and public awareness (Article 66(f))

# Environmental Considerations

The Act addresses environmental aspects of AI:

- Encourages development of energy-efficient AI systems
- Requires disclosure of energy consumption for general-purpose AI models (Annex XI, Section 1, point 2(e))
- Promotes standardization efforts for energy-efficient AI development (Article 40(2))
- Commission to report on progress in energy efficiency of AI systems (Article 112(6))

# Codes of Conduct

The Act encourages voluntary codes of conduct for non-high-risk AI systems (Article 95):

- Can cover some or all requirements applicable to high-risk systems
- May address specific issues like environmental sustainability, accessibility, and stakeholder participation
- Can be developed by individual providers, organizations, or with stakeholder involvement
- Commission and Member States to facilitate development of these codes
- Aim to promote responsible AI practices beyond mandatory requirements
- Can help smaller operators implement AI ethics principles

The AI Office will encourage and facilitate the development of these codes, involving relevant stakeholders in the process.

# AI Pact

The Commission has initiated the AI Pact to encourage early implementation of the Act:

- Voluntary initiative for organizations to prepare for compliance
- Two-pillar approach:
  • Pillar I: Engagement and knowledge sharing among participants
  • Pillar II: Voluntary commitments to implement AI Act requirements early
- Includes workshops, best practice sharing, and public pledges by companies
- Aims to accelerate adoption of responsible AI practices ahead of legal deadlines

Specific commitments companies are encouraged to make under the AI Pact:

1. Adopt an AI governance strategy
2. Identify and map AI systems likely to be categorized as high-risk
3. Promote AI awareness and literacy among staff
4. Implement measures for human oversight of AI systems
5. Develop processes for risk assessment and mitigation
6. Establish transparency measures, including for AI-generated content
7. Commit to responsible data governance practices
8. Engage in sharing best practices with other participants

# Implementation Timeline

Key dates for implementation of the Act:

2024:

- 12 July: Official publication in the Official Journal of the European Union
- 1 August: Entry into force
- 2 November: Deadline for Member States to identify authorities responsible for fundamental rights protection

2025:

- 2 February: Prohibitions on certain AI practices apply
- 2 May: Codes of practice to be ready
- 2 August: Rules on GPAI models, governance structures, and penalties apply
- 2 August: Member States to designate national competent authorities

2026:

- 2 February: Commission to provide guidelines on high-risk classification
- 2 August: Most provisions apply, including requirements for high-risk AI systems
- 2 August: AI regulatory sandboxes to be operational in Member States

2027:

- 2 August: Rules on high-risk AI systems that are safety components of products apply
- 2 August: GPAI models placed on market before August 2025 must comply

2028:

- 2 August: Commission to evaluate functioning of the AI Office
- 2 August: First evaluation of impact of voluntary codes of conduct
- 2 August: Commission to evaluate progress on energy-efficient development of GPAI models

2029:

- 2 August: First comprehensive Commission report on evaluation and review of the Act

2030:

- 2 August: AI systems used by public authorities must comply
- 31 December: AI components of large-scale EU IT systems must comply

2031:

- 2 August: Commission to assess enforcement of the Act

# Penalties for Infringement

The Act requires Member States to lay down rules on penalties for infringements:

- Penalties must be effective, proportionate, and dissuasive
- Member States must notify the Commission of these rules by 2 August 2025
- Penalties should take into account the interests of SMEs and start-ups

Maximum administrative fines for infringements:

- Up to €35 million or 7% of total worldwide annual turnover for violations of prohibited practices or data requirements
- Up to €15 million or 3% of turnover for other violations of the Act
- Up to €7.5 million or 1.5% of turnover for supplying incorrect information to authorities

Factors to be considered when imposing penalties:

- Nature, gravity, and duration of the infringement
- Intentional or negligent character of the infringement
- Actions taken to mitigate damage
- Relevant previous infringements
- Degree of cooperation with authorities
- Size and market share of the entity

The European Data Protection Supervisor has the power to impose fines on Union institutions, bodies, offices, and agencies.

The Act also provides for effective judicial remedies for affected persons and protections for whistleblowers reporting violations.

# How EU AI Act builds on GDPR

## Scope and Application

- **GDPR**: Applies to any organization processing personal data of EU residents, regardless of location. (Article 3)
- **AI Act**: Applies to AI systems used in the EU, regardless of the provider's location (Article 2).

## Rights of Individuals

- **GDPR Foundations**
  - Access: Right to know what personal data is collected and how it's used. (Article 15)
  - Rectification: Right to correct inaccurate or incomplete personal data. (Article 16)
  - Erasure: "Right to be forgotten" - request deletion of personal data under certain circumstances. (Article 17)
  - Data portability: Right to obtain and transfer personal data in a machine-readable format. (Article 20)
- **AI Act Extensions**
  - Focuses on rights related to high-risk AI systems.
  - Right to information: Users must be informed when interacting with certain AI systems (Article 50).
  - Right to explanation: For high-risk AI systems, providers must ensure the operation is sufficiently transparent to enable users to interpret the system's output and use it appropriately (Article 13).
  - Right to human oversight: For high-risk AI systems, appropriate human oversight measures must be ensured (Article 14).
  - Right to lodge a complaint: Any person can lodge a complaint with a relevant market surveillance authority about non-compliance with the AI Act (Article 85).

## Risk-Based Approach

- **GDPR**
  - Data Protection Impact Assessments (DPIAs): Formal risk analysis for high-risk activities. (Article 35)
- **AI Act**
  - Extends risk-based approach to AI.
  - Categorizes systems into unacceptable, high, limited, and minimal risk levels (Chapters II and III).
  - Mandates assessments for high-risk AI systems, including evaluation of fundamental rights impacts.

## Accountability and Documentation

- **GDPR**
  - Requires controllers and processors to maintain records of processing activities. (Article 30)
  - Specifies information to be included in records (e.g., purposes of processing, categories of data subjects and personal data, recipients). (Article 30)
- **AI Act**
  - Requires extensive technical documentation and record-keeping for AI systems (Article 11 and Annex IV).
  - Applies to all providers and deployers of high-risk AI systems, regardless of organization size.
  - Mandates detailed documentation covering the entire lifecycle of the AI system.
  - Requires logging capabilities for monitoring AI system operation.
  - Specifies records must include information on development process, training data, testing procedures, and performance metrics.
  - Requires retention of records for at least 10 years after the AI system is placed on market or put into service (Article 18(1)).

## Automated Decision-Making

- **GDPR**
  - Provides safeguards against solely automated decisions with legal or similarly significant effects. (Article 22)
  - Gives right to obtain human intervention, express point of view, and contest the decision. (Article 22)
- **AI Act**
  - Expands on GDPR with specific rules for high-risk AI systems used in decision-making.
  - Requires human oversight for high-risk AI systems (Article 14).
  - Mandates that high-risk AI systems be designed to allow for human interpretation of outputs (Article 13).
  - Requires clear documentation and instructions for use of high-risk AI systems (Article 13).
- **Example (High-Risk AI in Recruitment)**
  - The AI system must be designed with appropriate human-machine interface tools (Article 14).
  - Human overseer must be able to fully understand the AI system's capabilities and limitations (Article 14).
  - Human overseer must be able to interpret the AI system's output correctly (Article 14).
  - Human overseer must be able to decide not to use the AI system or to disregard, override or reverse its output (Article 14).
  - Provider must give clear information about the AI system's capabilities and limitations in the instructions for use (Article 13).

## Transparency and Explainability

- **GDPR**
  - Requires clear and transparent information about data collection and use. (Articles 13 and 14)
  - Mandates concise, intelligible, and easily accessible information. (Articles 12, 13, and 14)
  - Gives right to obtain information about logic in automated decision-making, including profiling. (Articles 13, 14, and 15)
- **AI Act**
  - Requires clear documentation and instructions for high-risk AI systems (Article 13).
  - Mandates disclosure of AI in systems interacting with natural persons (e.g., chatbots).
  - Introduces "right to explanation" for decisions by high-risk AI systems (Article 50).
  - Requires disclosure of deep fakes and other AI-generated content.

## Notification of Incidents

- **GDPR**
  - Requires notification of personal data breaches to authorities within 72 hours. (Article 33)
  - Mandates notification to affected individuals for high-risk breaches. (Article 34)
- **AI Act**
  - Extends beyond data breaches to cover serious incidents and malfunctions of AI systems.
  - Requires immediate reporting of serious incidents or malfunctions to authorities (Article 73).
  - Mandates users (deployers) of high-risk AI systems to report serious incidents to providers or distributors.

## Compliance and Penalties

- **GDPR**
  - Creates European Data Protection Board for EU-level coordination. (Article 68)
  - Requires Data Protection Officers for certain organizations. (Article 37)
  - Fines up to €20 million or 4% of global annual turnover, whichever is higher. (Article 83)
- **AI Act**
  - Creates European Artificial Intelligence Board for coordination (Article 65).
  - Establishes AI Office within European Commission.
  - Sets maximum fines of €35 million or 7% of global turnover for most serious violations (Article 99).

# Essential Activities for Data Governance Teams

- These are some of the key activities that data governance teams should focus on to ensure compliance with the EU AI Act:

## Data Quality and Governance (Article 10)

- Training, validation, and testing data sets must meet quality criteria.
- Relevant data preparation and processing steps must be documented.
- Data sets must be relevant, representative, free of errors, and complete.

## Bias Detection and Mitigation (Article 10)

- Examine training, validation, and testing data for possible biases.
- Detect and address possible biases that may affect health, safety, and fundamental rights.

## Technical Documentation (Article 10)

- Detailed documentation required covering the entire AI system lifecycle.
- Must include information on system design, development process, and operational details.

## Record-Keeping and Logging (Article 10)

- Automatic recording of events ('logs') throughout the AI system's lifetime.
- Logging must enable monitoring of the system's operation.

## Transparency and User Information (Article 10)

- High-risk AI systems must be sufficiently transparent to enable users to interpret and use the system's output appropriately.
- Clear and adequate information must be provided to users, including the system's capabilities and limitations.

## Human Oversight (Article 10)

- Measures must be in place to allow effective oversight by natural persons.
- This includes the ability to fully understand the AI system's capabilities and to interpret its output.
  I'd be happy to review and improve this text for you. The content is already well-structured and informative, but I'll make some enhancements to improve clarity, consistency, and completeness. Here's the revised version:

# Essential Activities for AI/ML Teams

- These are some of the key activities that AI/ML departments should focus on to ensure compliance with the EU AI Act

## Algorithmic Impact Assessments

- Conduct thorough evaluations of potential risks to fundamental rights
- Assess environmental and societal impacts of AI systems
- Analyze and quantify potential discriminatory effects
- Identify and develop strategies to mitigate unintended consequences
- Document assessment results, mitigation strategies, and ongoing monitoring plans

## Training Data Management

- Implement robust version control systems for datasets
- Establish and document data update and refresh procedures
- Ensure proper storage, encryption, and security of training data
- Maintain comprehensive documentation of data sources, collection methods, and preprocessing steps
- Implement advanced data cataloging systems for improved searchability and governance

## Synthetic Data Generation

- Develop capabilities for generating high-quality synthetic datasets
- Implement rigorous validation processes to ensure synthetic data accurately represents real-world scenarios
- Document synthetic data generation methods, including algorithms and parameters used
- Assess and address legal and ethical implications of synthetic data use
- Establish guidelines for appropriate use of synthetic data in AI model development and testing

## AI Model Lifecycle Management

- Implement comprehensive model versioning and change management processes
- Establish standardized procedures for model testing, validation, and performance benchmarking
- Define clear criteria for model deployment, monitoring, and retirement
- Continuously monitor model performance in production environments
- Develop and implement model update and retraining processes, including triggers for retraining

## Model Documentation

- Develop and enforce comprehensive documentation practices across all AI projects
- Include detailed information on system architecture, algorithms, hyperparameters, and training processes
- Document performance metrics, limitations, and potential biases of AI models
- Maintain meticulous records of model versions, updates, and the rationale behind changes
- Ensure documentation is accessible, understandable, and readily available to regulators and auditors

## Audit Trails for AI Decisions

- Implement robust logging mechanisms to capture all AI system decisions and interactions
- Ensure audit trails comprehensively capture relevant decision factors and intermediate steps
- Establish processes for regular review, analysis, and reporting of audit logs
- Maintain audit trails for the required retention period as specified by regulations
- Implement technical measures to ensure audit trail data is tamper-proof, secure, and compliant with data protection regulations

## Transparency and Explainability

- Develop methods to enhance the interpretability of AI models
- Create user-friendly interfaces for explaining AI decisions to affected individuals
- Implement techniques for generating human-readable explanations of model outputs
- Establish processes for handling user inquiries about AI-driven decisions
- Regularly assess and improve the quality and comprehensibility of AI explanations

## Ongoing Compliance Monitoring

- Establish a dedicated team or role for AI compliance oversight
- Develop a compliance checklist aligned with EU AI Act requirements
- Conduct regular internal audits of AI systems and processes
- Stay informed about updates to AI regulations and adjust practices accordingly
- Foster a culture of ethical AI development and regulatory compliance within the organization
